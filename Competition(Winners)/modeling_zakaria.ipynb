{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "                                                                \n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor, AdaBoostRegressor,\\\n",
    "                            GradientBoostingRegressor, VotingRegressor, StackingRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_ready_zakaria.csv')\n",
    "test = pd.read_csv('test_ready_zakaria.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Brand              3000 non-null   object \n",
      " 1   VehicleModel       3000 non-null   object \n",
      " 2   ManufacturingYear  3000 non-null   int64  \n",
      " 3   Type               3000 non-null   object \n",
      " 4   rating             3000 non-null   float64\n",
      " 5   color              3000 non-null   object \n",
      " 6   Duty               3000 non-null   float64\n",
      " 7   fuel               3000 non-null   object \n",
      " 8   CylinderCount      3000 non-null   int64  \n",
      " 9   type of gear       3000 non-null   object \n",
      " 10  Odometer           3000 non-null   int64  \n",
      " 11  airbags            3000 non-null   int64  \n",
      " 12  Engine Volume      3000 non-null   float64\n",
      " 13  Engine Type        3000 non-null   object \n",
      " 14  ID                 3000 non-null   int64  \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 351.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         7000 non-null   int64  \n",
      " 1   Brand              7000 non-null   object \n",
      " 2   VehicleModel       7000 non-null   object \n",
      " 3   ManufacturingYear  7000 non-null   int64  \n",
      " 4   Type               7000 non-null   object \n",
      " 5   rating             7000 non-null   float64\n",
      " 6   color              7000 non-null   object \n",
      " 7   Duty               7000 non-null   float64\n",
      " 8   fuel               7000 non-null   object \n",
      " 9   CylinderCount      7000 non-null   int64  \n",
      " 10  type of gear       7000 non-null   object \n",
      " 11  Odometer           7000 non-null   int64  \n",
      " 12  airbags            7000 non-null   int64  \n",
      " 13  price              7000 non-null   int64  \n",
      " 14  Engine Volume      7000 non-null   float64\n",
      " 15  Engine Type        7000 non-null   object \n",
      "dtypes: float64(3), int64(6), object(7)\n",
      "memory usage: 875.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['price', 'Unnamed: 0', 'rating', 'color'], axis=1)\n",
    "y = train['price']\n",
    "\n",
    "cat_features = X.select_dtypes(include='object').columns\n",
    "num_features = X.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Brand', 'VehicleModel', 'Type', 'fuel', 'type of gear', 'Engine Type'], dtype='object'),\n",
       " Index(['ManufacturingYear', 'Duty', 'CylinderCount', 'Odometer', 'airbags',\n",
       "        'Engine Volume'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X.select_dtypes(include='object').columns\n",
    "num_features = X.select_dtypes(exclude='object').columns\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_transformer, cat_features),\n",
    "    ('num', num_transformer, num_features)\n",
    "])\n",
    "\n",
    "x_train_preprocessed = preprocessor.fit_transform(x_train)\n",
    "x_test_preprocessed = preprocessor.transform(x_test)\n",
    "\n",
    "x_train_preprocessed = pd.DataFrame(x_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE: 4991.706226278442\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=145)\n",
    "rf_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', rf)\n",
    "])\n",
    "rf_pipe.fit(x_train, y_train)\n",
    "rf_pred = rf_pipe.predict(x_test)\n",
    "rf_score = mean_absolute_error(y_test, rf_pred)\n",
    "print(f'Random Forest MAE: {rf_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees MAE: 5330.619663265306\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesRegressor(n_estimators = 140, random_state=42)\n",
    "et_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('et', et)\n",
    "])\n",
    "et_pipe.fit(x_train, y_train)\n",
    "et_pred = et_pipe.predict(x_test)\n",
    "et_score = mean_absolute_error(y_test, et_pred)\n",
    "print(f'Extra Trees MAE: {et_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE: 4987.405340960885\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', rf)\n",
    "])\n",
    "rf_pipe.fit(x_train, y_train)\n",
    "rf_pred = rf_pipe.predict(x_test)\n",
    "rf_score = mean_absolute_error(y_test, rf_pred)\n",
    "print(f'Random Forest MAE: {rf_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = test.drop(['ID', 'rating', 'color'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Brand              3000 non-null   object \n",
      " 1   VehicleModel       3000 non-null   object \n",
      " 2   ManufacturingYear  3000 non-null   int64  \n",
      " 3   Type               3000 non-null   object \n",
      " 4   Duty               3000 non-null   float64\n",
      " 5   fuel               3000 non-null   object \n",
      " 6   CylinderCount      3000 non-null   int64  \n",
      " 7   type of gear       3000 non-null   object \n",
      " 8   Odometer           3000 non-null   int64  \n",
      " 9   airbags            3000 non-null   int64  \n",
      " 10  Engine Volume      3000 non-null   float64\n",
      " 11  Engine Type        3000 non-null   object \n",
      "dtypes: float64(2), int64(4), object(6)\n",
      "memory usage: 281.4+ KB\n"
     ]
    }
   ],
   "source": [
    "to_predict.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['price'] = rf_pipe.predict(to_predict)\n",
    "submission.to_csv('late_submission_zakaria_rf_dropping_cols.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE: 4987.405340960885\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', rf)\n",
    "])\n",
    "rf_pipe.fit(x_train, y_train)\n",
    "rf_pred = rf_pipe.predict(x_test)\n",
    "rf_score = mean_absolute_error(y_test, rf_pred)\n",
    "print(f'Random Forest MAE: {rf_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['price'] = rf_pipe.predict(test.drop('ID', axis=1))\n",
    "submission.to_csv('late_submission_zakaria_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees MAE: 5340.067375\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees\n",
    "et = ExtraTreesRegressor(random_state=42)\n",
    "et_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('et', et)\n",
    "])\n",
    "et_pipe.fit(x_train, y_train)\n",
    "et_pred = et_pipe.predict(x_test)\n",
    "et_score = mean_absolute_error(y_test, et_pred)\n",
    "print(f'Extra Trees MAE: {et_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor MAE: 5061.747388290816\n"
     ]
    }
   ],
   "source": [
    "voting = VotingRegressor([\n",
    "    ('rf', rf),\n",
    "    ('et', et)\n",
    "])\n",
    "voting_pipe2 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting', voting)\n",
    "])\n",
    "voting_pipe2.fit(x_train, y_train)\n",
    "voting_pred2 = voting_pipe2.predict(x_test)\n",
    "voting_score2 = mean_absolute_error(y_test, voting_pred2)\n",
    "print(f'Voting Regressor MAE: {voting_score2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE: 5059.394404438775\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf', rf)\n",
    "])\n",
    "rf_pipe.fit(x_train, y_train)\n",
    "rf_pred = rf_pipe.predict(x_test)\n",
    "rf_score = mean_absolute_error(y_test, rf_pred)\n",
    "print(f'Random Forest MAE: {rf_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees MAE: 5330.619663265306\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesRegressor(n_estimators = 140, random_state=42)\n",
    "et_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('et', et)\n",
    "])\n",
    "et_pipe.fit(x_train, y_train)\n",
    "et_pred = et_pipe.predict(x_test)\n",
    "et_score = mean_absolute_error(y_test, et_pred)\n",
    "print(f'Extra Trees MAE: {et_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor MAE: 5060.198907423469\n"
     ]
    }
   ],
   "source": [
    "# Voting Regressor\n",
    "voting = VotingRegressor([\n",
    "    ('rf', rf),\n",
    "    ('et', et)\n",
    "])\n",
    "voting_pipe3 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting', voting)\n",
    "])\n",
    "voting_pipe3.fit(x_train, y_train)\n",
    "voting_pred3 = voting_pipe3.predict(x_test)\n",
    "voting_score3 = mean_absolute_error(y_test, voting_pred3)\n",
    "print(f'Voting Regressor MAE: {voting_score3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor MAE: 4909.757368808491\n"
     ]
    }
   ],
   "source": [
    "# stacking\n",
    "voting = VotingRegressor([\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('et', ExtraTreesRegressor(random_state=42, n_estimators=140))\n",
    "])\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "bag = BaggingRegressor(n_estimators=1300, random_state=42)\n",
    "lgb = LGBMRegressor(n_estimators=1500, verbosity=0)\n",
    "cb = CatBoostRegressor(iterations=1500, verbose=0)\n",
    "xgb = XGBRegressor(n_estimators=1500, verbosity=0)\n",
    "\n",
    "stacking = StackingRegressor([\n",
    "    ('voting', voting),\n",
    "    ('dt', dt),\n",
    "    ('rf',rf),\n",
    "    ('et',  et),\n",
    "    ('bag', bag),\n",
    "    ('lgb', lgb),\n",
    "    ('cb', cb),\n",
    "    ('xgb', xgb)\n",
    "], final_estimator=LinearRegression())\n",
    "\n",
    "stacking_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', stacking)\n",
    "])\n",
    "stacking_pipe.fit(x_train, y_train)\n",
    "stacking_pred = stacking_pipe.predict(x_test)\n",
    "stacking_score = mean_absolute_error(y_test, stacking_pred)\n",
    "print(f'Stacking Regressor MAE: {stacking_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['price'] = stacking_pipe.predict(test.drop('ID', axis=1))\n",
    "submission.to_csv('submission_zakaria_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor MAE: 4900.675839867733\n"
     ]
    }
   ],
   "source": [
    "# stacking\n",
    "voting = VotingRegressor([\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('et', ExtraTreesRegressor(random_state=42, n_estimators=140))\n",
    "])\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "bag = BaggingRegressor(n_estimators=1300, random_state=42)\n",
    "lgb = LGBMRegressor(n_estimators=1500, verbosity=0)\n",
    "cb = CatBoostRegressor(iterations=1500, verbose=0)\n",
    "xgb = XGBRegressor(n_estimators=1500, verbosity=0)\n",
    "hstgb = GradientBoostingRegressor()\n",
    "\n",
    "stacking = StackingRegressor([\n",
    "    ('voting', voting),\n",
    "    ('dt', dt),\n",
    "    ('rf',rf),\n",
    "    ('et',  et),\n",
    "    ('bag', bag),\n",
    "    ('lgb', lgb),\n",
    "    ('cb', cb),\n",
    "    ('xgb', xgb), \n",
    "    ('hstgb', hstgb)\n",
    "], final_estimator=LinearRegression())\n",
    "\n",
    "stacking_pipe2 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', stacking)\n",
    "])\n",
    "stacking_pipe2.fit(x_train, y_train)\n",
    "stacking_pred2 = stacking_pipe2.predict(x_test)\n",
    "stacking_score2 = mean_absolute_error(y_test, stacking_pred2)\n",
    "print(f'Stacking Regressor MAE: {stacking_score2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['price'] = stacking_pipe2.predict(test.drop('ID', axis=1))\n",
    "submission.to_csv('submission_zakaria_3_last_hope.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 245, in _count_physical_cores\n",
      "    raise ValueError(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor MAE: 4865.056608565888\n"
     ]
    }
   ],
   "source": [
    "# stacking\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "et = ExtraTreesRegressor(random_state=42, n_estimators=140)\n",
    "\n",
    "voting = VotingRegressor([\n",
    "    ('rf', rf),\n",
    "    ('et', et)\n",
    "])\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "bag = BaggingRegressor(n_estimators=1300, random_state=42)\n",
    "lgb = LGBMRegressor(n_estimators=1500, verbosity=0)\n",
    "cb = CatBoostRegressor(iterations=1500, verbose=0)\n",
    "xgb = XGBRegressor(n_estimators=1500, verbosity=0)\n",
    "gb = GradientBoostingRegressor()\n",
    "ada = AdaBoostRegressor()\n",
    "\n",
    "stacking = StackingRegressor([\n",
    "    ('voting', voting),\n",
    "    ('dt', dt),\n",
    "    ('rf',rf),\n",
    "    ('et',  et),\n",
    "    ('bag', bag),\n",
    "    ('lgb', lgb),\n",
    "    ('cb', cb),\n",
    "    ('xgb', xgb), \n",
    "    ('gb', gb),\n",
    "    ('ada', ada)\n",
    "], final_estimator=LinearRegression())\n",
    "\n",
    "stacking_pipe2 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('stacking', stacking)\n",
    "])\n",
    "stacking_pipe2.fit(x_train, y_train)\n",
    "stacking_pred2 = stacking_pipe2.predict(x_test)\n",
    "stacking_score2 = mean_absolute_error(y_test, stacking_pred2)\n",
    "print(f'Stacking Regressor MAE: {stacking_score2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['price'] = stacking_pipe2.predict(test.drop(['ID','rating', 'color'], axis=1))\n",
    "submission.to_csv('stacking_data_improved.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.DataFrame()\n",
    "submissions['ID'] = test['ID']\n",
    "submissions['price'] = stacking_pipe.predict(test.drop('ID', axis=1))\n",
    "submissions.to_csv('zakaria_basic_stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features2 = X.select_dtypes(include='object').columns\n",
    "num_features2 = X.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "X_encoded = pd.DataFrame(ohe.fit_transform(X[cat_features2]).toarray())\n",
    "\n",
    "X_processed = pd.concat([X[num_features2], X_encoded], axis=1)\n",
    "\n",
    "# Now you can safely convert the processed data to float32\n",
    "X_processed = X_processed.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "X_processed.columns = X_processed.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = int(X_processed.shape[0] * 0.8)\n",
    "X_train, y_train = X_processed[:offset], y[:offset]\n",
    "X_test, y_test = X_processed[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/42 [00:06<00:15,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNetCV model failed to execute\n",
      "Gram matrix passed in via 'precompute' parameter did not pass validation when a single element was checked - please check that it was computed properly. For element (267,268) we computed -4.475705146789551 but the user-supplied value was -4.475739002227783.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 11/42 [01:34<04:26,  8.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24056\\3921649613.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlazy_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\lazypredict\\Supervised.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m    601\u001b[0m                     )\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                 \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \"\"\"\n\u001b[0;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    604\u001b[0m         )\n\u001b[0;32m    605\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    607\u001b[0m                 delayed(func)(\n\u001b[0;32m    608\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m                 self.mean_, self.var_, self.n_samples_seen_ = _incremental_mean_and_var(\n\u001b[0m\u001b[0;32m    928\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36m_incremental_mean_and_var\u001b[1;34m(X, last_mean, last_variance, last_sample_count, sample_weight)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m             \u001b[0mcorrection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_accumulator_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mtemp\u001b[0m \u001b[1;33m**=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m             \u001b[0mnew_unnormalized_variance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_accumulator_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "lazy_reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=mean_absolute_error)\n",
    "\n",
    "\n",
    "models,predictions = lazy_reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.56</td>\n",
       "      <td>7642.60</td>\n",
       "      <td>12.76</td>\n",
       "      <td>5083.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.53</td>\n",
       "      <td>7931.84</td>\n",
       "      <td>23.34</td>\n",
       "      <td>5320.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8072.09</td>\n",
       "      <td>0.72</td>\n",
       "      <td>5560.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8090.10</td>\n",
       "      <td>13.88</td>\n",
       "      <td>5600.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8189.50</td>\n",
       "      <td>3.30</td>\n",
       "      <td>5704.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.48</td>\n",
       "      <td>8281.97</td>\n",
       "      <td>1.70</td>\n",
       "      <td>5495.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.43</td>\n",
       "      <td>8743.71</td>\n",
       "      <td>5.24</td>\n",
       "      <td>6424.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9928.25</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7704.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>9935.01</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7721.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9966.24</td>\n",
       "      <td>2.25</td>\n",
       "      <td>7728.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9967.38</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7730.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9967.38</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7730.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9967.38</td>\n",
       "      <td>0.47</td>\n",
       "      <td>7730.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9988.06</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7697.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>9988.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7697.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10029.01</td>\n",
       "      <td>1.07</td>\n",
       "      <td>7808.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GammaRegressor</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10050.23</td>\n",
       "      <td>0.56</td>\n",
       "      <td>7721.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10055.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>7765.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10059.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7767.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10076.44</td>\n",
       "      <td>1.92</td>\n",
       "      <td>7768.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>10093.51</td>\n",
       "      <td>0.66</td>\n",
       "      <td>7534.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>10143.88</td>\n",
       "      <td>2.31</td>\n",
       "      <td>8129.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>10148.09</td>\n",
       "      <td>22.44</td>\n",
       "      <td>7873.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10158.77</td>\n",
       "      <td>3.60</td>\n",
       "      <td>7725.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10437.89</td>\n",
       "      <td>5.92</td>\n",
       "      <td>7681.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.17</td>\n",
       "      <td>10495.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>6643.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.14</td>\n",
       "      <td>10693.25</td>\n",
       "      <td>0.71</td>\n",
       "      <td>7704.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10983.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>7124.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>11538.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>9037.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>11681.25</td>\n",
       "      <td>18.34</td>\n",
       "      <td>8917.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>11685.35</td>\n",
       "      <td>13.12</td>\n",
       "      <td>8924.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>11687.87</td>\n",
       "      <td>5761.62</td>\n",
       "      <td>8928.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-1.85</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>15323.81</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11223.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-2.71</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>17468.88</td>\n",
       "      <td>1.51</td>\n",
       "      <td>14694.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>-19.35</td>\n",
       "      <td>-11.58</td>\n",
       "      <td>40923.46</td>\n",
       "      <td>67.59</td>\n",
       "      <td>15475.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>-3159856196.34</td>\n",
       "      <td>-1953735246.11</td>\n",
       "      <td>510004928.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>39989944.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>-3159856196.34</td>\n",
       "      <td>-1953735246.11</td>\n",
       "      <td>510004928.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>39989944.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>-21739089485.07</td>\n",
       "      <td>-13441252611.90</td>\n",
       "      <td>1337708288.00</td>\n",
       "      <td>12.62</td>\n",
       "      <td>289542784.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>-316002964420.03</td>\n",
       "      <td>-195384248908.36</td>\n",
       "      <td>5100189675.72</td>\n",
       "      <td>0.24</td>\n",
       "      <td>960749900.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.52</td>\n",
       "      <td>13372390102081113809244651520.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Adjusted R-Squared        R-Squared  \\\n",
       "Model                                                                \n",
       "RandomForestRegressor                        0.29             0.56   \n",
       "ExtraTreesRegressor                          0.24             0.53   \n",
       "LGBMRegressor                                0.21             0.51   \n",
       "HistGradientBoostingRegressor                0.20             0.51   \n",
       "XGBRegressor                                 0.19             0.50   \n",
       "BaggingRegressor                             0.17             0.48   \n",
       "GradientBoostingRegressor                    0.07             0.43   \n",
       "BayesianRidge                               -0.20             0.26   \n",
       "ElasticNet                                  -0.20             0.26   \n",
       "LarsCV                                      -0.21             0.25   \n",
       "LassoLarsCV                                 -0.21             0.25   \n",
       "LassoLars                                   -0.21             0.25   \n",
       "LassoLarsIC                                 -0.21             0.25   \n",
       "OrthogonalMatchingPursuitCV                 -0.21             0.25   \n",
       "OrthogonalMatchingPursuit                   -0.21             0.25   \n",
       "TweedieRegressor                            -0.22             0.24   \n",
       "GammaRegressor                              -0.23             0.24   \n",
       "RidgeCV                                     -0.23             0.24   \n",
       "Ridge                                       -0.23             0.24   \n",
       "Lasso                                       -0.23             0.24   \n",
       "KNeighborsRegressor                         -0.24             0.23   \n",
       "AdaBoostRegressor                           -0.25             0.23   \n",
       "MLPRegressor                                -0.25             0.23   \n",
       "PoissonRegressor                            -0.25             0.22   \n",
       "HuberRegressor                              -0.32             0.18   \n",
       "DecisionTreeRegressor                       -0.34             0.17   \n",
       "PassiveAggressiveRegressor                  -0.39             0.14   \n",
       "ExtraTreeRegressor                          -0.47             0.09   \n",
       "DummyRegressor                              -0.62            -0.00   \n",
       "SVR                                         -0.66            -0.02   \n",
       "NuSVR                                       -0.66            -0.03   \n",
       "QuantileRegressor                           -0.66            -0.03   \n",
       "LinearSVR                                   -1.85            -0.76   \n",
       "KernelRidge                                 -2.71            -1.29   \n",
       "GaussianProcessRegressor                   -19.35           -11.58   \n",
       "TransformedTargetRegressor         -3159856196.34   -1953735246.11   \n",
       "LinearRegression                   -3159856196.34   -1953735246.11   \n",
       "RANSACRegressor                   -21739089485.07  -13441252611.90   \n",
       "SGDRegressor                     -316002964420.03 -195384248908.36   \n",
       "Lars                                         -inf             -inf   \n",
       "\n",
       "                                       RMSE  Time Taken  \\\n",
       "Model                                                     \n",
       "RandomForestRegressor               7642.60       12.76   \n",
       "ExtraTreesRegressor                 7931.84       23.34   \n",
       "LGBMRegressor                       8072.09        0.72   \n",
       "HistGradientBoostingRegressor       8090.10       13.88   \n",
       "XGBRegressor                        8189.50        3.30   \n",
       "BaggingRegressor                    8281.97        1.70   \n",
       "GradientBoostingRegressor           8743.71        5.24   \n",
       "BayesianRidge                       9928.25        0.74   \n",
       "ElasticNet                          9935.01        0.27   \n",
       "LarsCV                              9966.24        2.25   \n",
       "LassoLarsCV                         9967.38        1.85   \n",
       "LassoLars                           9967.38        0.36   \n",
       "LassoLarsIC                         9967.38        0.47   \n",
       "OrthogonalMatchingPursuitCV         9988.06        0.95   \n",
       "OrthogonalMatchingPursuit           9988.26        0.26   \n",
       "TweedieRegressor                   10029.01        1.07   \n",
       "GammaRegressor                     10050.23        0.56   \n",
       "RidgeCV                            10055.32        0.66   \n",
       "Ridge                              10059.24        0.24   \n",
       "Lasso                              10076.44        1.92   \n",
       "KNeighborsRegressor                10093.51        0.66   \n",
       "AdaBoostRegressor                  10143.88        2.31   \n",
       "MLPRegressor                       10148.09       22.44   \n",
       "PoissonRegressor                   10158.77        3.60   \n",
       "HuberRegressor                     10437.89        5.92   \n",
       "DecisionTreeRegressor              10495.32        0.43   \n",
       "PassiveAggressiveRegressor         10693.25        0.71   \n",
       "ExtraTreeRegressor                 10983.28        0.41   \n",
       "DummyRegressor                     11538.29        0.18   \n",
       "SVR                                11681.25       18.34   \n",
       "NuSVR                              11685.35       13.12   \n",
       "QuantileRegressor                  11687.87     5761.62   \n",
       "LinearSVR                          15323.81        0.32   \n",
       "KernelRidge                        17468.88        1.51   \n",
       "GaussianProcessRegressor           40923.46       67.59   \n",
       "TransformedTargetRegressor     510004928.00        0.31   \n",
       "LinearRegression               510004928.00        0.34   \n",
       "RANSACRegressor               1337708288.00       12.62   \n",
       "SGDRegressor                  5100189675.72        0.24   \n",
       "Lars                                    inf        0.52   \n",
       "\n",
       "                                           mean_absolute_error  \n",
       "Model                                                           \n",
       "RandomForestRegressor                                  5083.90  \n",
       "ExtraTreesRegressor                                    5320.67  \n",
       "LGBMRegressor                                          5560.46  \n",
       "HistGradientBoostingRegressor                          5600.52  \n",
       "XGBRegressor                                           5704.30  \n",
       "BaggingRegressor                                       5495.73  \n",
       "GradientBoostingRegressor                              6424.41  \n",
       "BayesianRidge                                          7704.20  \n",
       "ElasticNet                                             7721.12  \n",
       "LarsCV                                                 7728.28  \n",
       "LassoLarsCV                                            7730.26  \n",
       "LassoLars                                              7730.26  \n",
       "LassoLarsIC                                            7730.26  \n",
       "OrthogonalMatchingPursuitCV                            7697.84  \n",
       "OrthogonalMatchingPursuit                              7697.34  \n",
       "TweedieRegressor                                       7808.67  \n",
       "GammaRegressor                                         7721.55  \n",
       "RidgeCV                                                7765.10  \n",
       "Ridge                                                  7767.93  \n",
       "Lasso                                                  7768.56  \n",
       "KNeighborsRegressor                                    7534.36  \n",
       "AdaBoostRegressor                                      8129.11  \n",
       "MLPRegressor                                           7873.75  \n",
       "PoissonRegressor                                       7725.14  \n",
       "HuberRegressor                                         7681.93  \n",
       "DecisionTreeRegressor                                  6643.01  \n",
       "PassiveAggressiveRegressor                             7704.67  \n",
       "ExtraTreeRegressor                                     7124.25  \n",
       "DummyRegressor                                         9037.63  \n",
       "SVR                                                    8917.44  \n",
       "NuSVR                                                  8924.24  \n",
       "QuantileRegressor                                      8928.97  \n",
       "LinearSVR                                             11223.10  \n",
       "KernelRidge                                           14694.60  \n",
       "GaussianProcessRegressor                              15475.57  \n",
       "TransformedTargetRegressor                         39989944.00  \n",
       "LinearRegression                                   39989944.00  \n",
       "RANSACRegressor                                   289542784.00  \n",
       "SGDRegressor                                      960749900.38  \n",
       "Lars                          13372390102081113809244651520.00  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 904\n",
      "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 199\n",
      "[LightGBM] [Info] Start training from score 14406.612679\n",
      "LGBM MAE: 9277.984796648303\n"
     ]
    }
   ],
   "source": [
    "# lgbm\n",
    "lgbm = LGBMRegressor(random_state=42)\n",
    "lgbm_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', lgbm)\n",
    "])\n",
    "lgbm_pipe.fit(x_train, y_train)\n",
    "lgbm_pred = lgbm_pipe.predict(x_test)\n",
    "lgbm_score = mean_absolute_error(y_test, lgbm_pred)\n",
    "print(f'LGBM MAE: {lgbm_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
